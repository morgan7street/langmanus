# if true, use conf.yaml, else use original .env config, default false
USE_CONF: true

# LLM Config
## follow litellm config: https://docs.litellm.ai/docs/providers
REASONING_MODEL:
  model: "google/gemini-2.5-pro-exp-03-25:free"
 # api_key: $REASONING_API_KEY
 # api_base: $REASONING_BASE_URL

BASIC_MODEL:
  model: "deepseek/deepseek-chat-v3-0324:free"
 # api_base: $AZURE_API_BASE
 # api_version: $AZURE_API_VERSION
 # api_key: $AZURE_API_KEY

VISION_MODEL:
  model: "qwen/qwen2.5-vl-72b-instruct:free"
 # api_base: $AZURE_API_BASE
 # api_version: $AZURE_API_VERSION
 # api_key: $AZURE_API_KEY
